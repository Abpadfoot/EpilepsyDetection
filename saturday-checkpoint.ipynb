{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import os\n",
    "import pywt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirA =\"./Datasets/setB/\"\n",
    "tempA = []\n",
    "for file in os.listdir(dirA):\n",
    "    fl = dirA + file\n",
    "    tempA.append(fl)\n",
    "tempA = sorted(tempA)    # class: 1     val:  -1\n",
    "\n",
    "dirD=\"./Datasets/setC/\"\n",
    "tempD = []\n",
    "for file in os.listdir(dirD):\n",
    "    fl = dirD + file\n",
    "    tempD.append(fl)\n",
    "tempD = sorted(tempD)   # class:2       val: 0\n",
    "    \n",
    "dirE=\"./Datasets/setE/\"\n",
    "tempE = []\n",
    "for file in os.listdir(dirE):\n",
    "    fl = dirE + file\n",
    "    tempE.append(fl)\n",
    "tempE = sorted(tempE)   # class: 3        val: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n"
     ]
    }
   ],
   "source": [
    "ta=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempA)):\n",
    "    x = pd.read_table(tempA[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    ta.append(x)\n",
    "    \n",
    "td=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempD)):\n",
    "    x = pd.read_table(tempD[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    td.append(x)\n",
    "    \n",
    "te=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempE)):\n",
    "    x = pd.read_table(tempE[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    te.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def table(table):\n",
    "    big_table = None\n",
    "    for ta in table:\n",
    "        big_table = pd.concat([big_table, ta],axis=1)\n",
    "    return big_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigA = table(ta)\n",
    "bigD = table(td)\n",
    "bigE = table(te)\n",
    "head = list(bigA.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigA.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creat_mat(mat):\n",
    "    matx = np.zeros((len(mat),(len(head))))\n",
    "    for i in range(len(head)):\n",
    "        matx[:,i] = mat[head[i]]\n",
    "        sleep(0.01)\n",
    "    return matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matA = creat_mat(bigA) # : refers to healthy data\n",
    "matD = creat_mat(bigD) # : refers to Inter-ictal (transition between healthy to seizure)\n",
    "matE = creat_mat(bigE) # : of ictal or seizures\n",
    "\n",
    "matA = np.nan_to_num(matA) # matB[:,0] --- > channel 0, matB[:,1] --- > channel 1 like that\n",
    "matD = np.nan_to_num(matD)\n",
    "matE = np.nan_to_num(matE)\n",
    "\n",
    "\n",
    "# 4097 data point per channel \n",
    "# 173.61 Hz sample rate and there are 4097 data point for each channel\n",
    "# total 100 channel are their\n",
    "# 4097/173.61 = 23.59 sec \n",
    "# the raw data from one of the channels for the 23.59 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_size = 4\n",
    "columns_name = list()\n",
    "for i in range(feature_size):\n",
    "    columns_name = columns_name + ['f'+str(i+1)]\n",
    "columns_name = columns_name + ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(mat):\n",
    "    Kmax = 5\n",
    "    Tau  = 4\n",
    "    DE   = 10\n",
    "    M    = 10\n",
    "    R    = 0.3\n",
    "    Band = np.arange(1,86)\n",
    "    Fs   = 173\n",
    "    #fft = np.fft.fft(mat)\n",
    "    #mat = np.fft.ifft(fft[0:1500])\n",
    "    #mat = abs(np.fft.ifft(fft[0:1000]))\n",
    "    lis = list()\n",
    "    #lis = lis + [np.max(mat)]\n",
    "    #ct = 0\n",
    "    #ma = 0\n",
    "    #mat1 = mat>75 \n",
    "    #for i in range(len(mat1)-1):\n",
    "    #    if(mat1[i]==mat1[i+1]):\n",
    "    #        if(mat1[i]==1):\n",
    "    #            ct = ct+1\n",
    "    #            ma = max(ma,ct)\n",
    "    #        else: \n",
    "    #            ct = 0\n",
    "    #lis = lis + [ma]\n",
    "    #lis = lis + [pyeeg.dfa(mat)]                 #DFA\n",
    "    #lis = lis + [pyeeg.hfd(mat,Kmax)]            #HFD \n",
    "    #lis = lis + [pyeeg.svd_entropy(mat,Tau,DE)]  #SVD_Entropy\n",
    "    #lis = lis + [pyeeg.fisher_info(mat,Tau,DE)]  #Fisher_Information\n",
    "    #lis = lis + [pyeeg.pfd(mat)]                 #PFD\n",
    "    #lis = lis + [np.mean(pywt.wavedec(mat,'db2',level=2)[0])]\n",
    "    #lis = lis + [np.min(pywt.wavedec(mat,'db2',level=2)[0])]\n",
    "    #lis = lis + [np.max(pywt.wavedec(mat,'db2',level=2)[0])]\n",
    "    lis = lis + [np.std(pywt.wavedec(mat,'db8',level=8)[0])]\n",
    "    #lis = lis + [np.mean(pywt.wavedec(mat,'db2',level=2)[1])]\n",
    "    #lis = lis + [np.min(pywt.wavedec(mat,'db2',level=2)[1])]\n",
    "    #lis = lis + [np.max(pywt.wavedec(mat,'db4',level=8)[3])]\n",
    "    lis = lis + [np.std(pywt.wavedec(mat,'db8',level=8)[4])]\n",
    "    #lis = lis + [np.mean(pywt.wavedec(mat,'db2',level=2)[2])]\n",
    "    #lis = lis + [np.min(pywt.wavedec(mat,'db2',level=2)[2])]\n",
    "    #lis = lis + [np.max(pywt.wavedec(mat,'db2',level=2)[2])]\n",
    "    lis = lis + [np.std(pywt.wavedec(mat,'db8',level=8)[5])]\n",
    "    lis = lis + [np.std(pywt.wavedec(mat,'db8',level=8)[6])]\n",
    "    #lis = lis + [np.std(pywt.wavedec(mat,'db4',level=8)[7])]\n",
    "    \n",
    "    #lis = lis + [np.max(abs(fft))]\n",
    "    #lis = lis + [np.min(abs(fft))]\n",
    "    #lis = lis + [np.mean(abs(fft))]\n",
    "    #lis = lis + [np.std(abs(fft))]\n",
    "    #lis = lis + [np.max(mat)]\n",
    "    #lis = lis + [np.min(mat)]\n",
    "    #lis = lis + [np.mean(mat)]\n",
    "    #lis = lis + [np.std(mat)]\n",
    "    sleep(0.01)\n",
    "             \n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MftA = np.zeros((100,feature_size + 1))\n",
    "\n",
    "for i in range(100):\n",
    "    MftA[i,:] = features(matA[:,i]) + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MftD = np.zeros((100,feature_size + 1))\n",
    "\n",
    "for i in range(100):\n",
    "    MftD[i,:] = features(matD[:,i]) + [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MftE = np.zeros((100,feature_size + 1))\n",
    "\n",
    "for i in range(100):\n",
    "    MftE[i,:] = features(matE[:,i]) + [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FCM_A = pd.DataFrame(MftA,columns=columns_name)\n",
    "FCM_D = pd.DataFrame(MftD,columns=columns_name)\n",
    "FCM_E = pd.DataFrame(MftE,columns=columns_name)\n",
    "#FCM_B.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TotalDataset = pd.concat([FCM_A,FCM_D,FCM_E],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = TotalDataset[columns_name[:-1]]\n",
    "y = TotalDataset[['class']]\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9696969696969697"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = SVC(kernel=\"linear\", C=0.025)\n",
    "a.fit(X_train,y_train)\n",
    "a.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = a.predict(X_test[0:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct=0\n",
    "for i in range(99):\n",
    "    if(p[i]==y_test[i]):\n",
    "        ct=ct+1\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_score=[]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        clf_score.append([score,name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9393939393939394, 'Nearest Neighbors'],\n",
       " [0.9696969696969697, 'Linear SVM'],\n",
       " [0.40404040404040403, 'Gaussian Process'],\n",
       " [0.9393939393939394, 'Decision Tree'],\n",
       " [0.9494949494949495, 'Random Forest'],\n",
       " [0.9393939393939394, 'AdaBoost'],\n",
       " [0.9595959595959596, 'Naive Bayes']]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TotalDataset = pd.concat([FCM_A,FCM_E],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = TotalDataset[columns_name[:-1]]\n",
    "y = TotalDataset[['class']]\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_score=[]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        clf_score.append([score,name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9666666666666667, 'Nearest Neighbors'],\n",
       " [1.0, 'Linear SVM'],\n",
       " [0.9, 'Gaussian Process'],\n",
       " [1.0, 'Decision Tree'],\n",
       " [0.9666666666666667, 'Random Forest'],\n",
       " [1.0, 'AdaBoost'],\n",
       " [0.9666666666666667, 'Naive Bayes']]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
